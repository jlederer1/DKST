{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules reloaded and re-imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Reload all modules in case they are under development\n",
    "import importlib\n",
    "from dkst.utils import KST_utils, DKST_utils, set_operations, relations\n",
    "from dkst import dkst_datasets, models\n",
    "\n",
    "# Reload each module\n",
    "importlib.reload(KST_utils)\n",
    "importlib.reload(DKST_utils)\n",
    "importlib.reload(set_operations)\n",
    "importlib.reload(relations)\n",
    "importlib.reload(dkst_datasets)\n",
    "importlib.reload(models)\n",
    "\n",
    "# Import everything from the modules\n",
    "from dkst.utils.KST_utils import *\n",
    "from dkst.utils.DKST_utils import *\n",
    "from dkst.utils.set_operations import *\n",
    "from dkst.utils.relations import *\n",
    "from dkst.dkst_datasets import *\n",
    "from dkst.models import *\n",
    "\n",
    "import gc\n",
    "from torch.utils.data import DataLoader, random_split, ConcatDataset\n",
    "\n",
    "print(\"Modules reloaded and re-imported successfully.\")\n",
    "config_path = os.path.abspath(\"../data/config/config_data_07.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Dataset configuration \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m D0 \u001b[38;5;241m=\u001b[39m \u001b[43mDKSTDataset02\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# split dataset 80/20\u001b[39;00m\n\u001b[1;32m      5\u001b[0m train_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0.8\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(D0))\n",
      "File \u001b[0;32m~/Documents/UNI/Extrakurrikular/dkst/dkst/dkst_datasets.py:47\u001b[0m, in \u001b[0;36mDKSTDataset02.__init__\u001b[0;34m(self, config_path)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# data\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstructures \u001b[38;5;241m=\u001b[39m sample_knowledge_structures(m\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m\"\u001b[39m], num_samples\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_structures\u001b[39m\u001b[38;5;124m'\u001b[39m], no_dublicates\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno_dublicates\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconditionals \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([compute_conditionals(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstructures[:, :, i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstructures\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m])])\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponses \u001b[38;5;241m=\u001b[39m sample_response_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstructures, config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_patterns\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28;01mNone\u001b[39;00m, config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeta\u001b[39m\u001b[38;5;124m\"\u001b[39m], config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meta\u001b[39m\u001b[38;5;124m\"\u001b[39m], config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m], config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfactor\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate2idx \u001b[38;5;241m=\u001b[39m create_state2idx(config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m\"\u001b[39m], config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEOS_TOKEN\u001b[39m\u001b[38;5;124m'\u001b[39m], config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPAD_TOKEN\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/Documents/UNI/Extrakurrikular/dkst/dkst/dkst_datasets.py:47\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# data\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstructures \u001b[38;5;241m=\u001b[39m sample_knowledge_structures(m\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m\"\u001b[39m], num_samples\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_structures\u001b[39m\u001b[38;5;124m'\u001b[39m], no_dublicates\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno_dublicates\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconditionals \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mcompute_conditionals\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructures\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstructures\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m])])\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponses \u001b[38;5;241m=\u001b[39m sample_response_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstructures, config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_patterns\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28;01mNone\u001b[39;00m, config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeta\u001b[39m\u001b[38;5;124m\"\u001b[39m], config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meta\u001b[39m\u001b[38;5;124m\"\u001b[39m], config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m], config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfactor\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate2idx \u001b[38;5;241m=\u001b[39m create_state2idx(config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m\"\u001b[39m], config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEOS_TOKEN\u001b[39m\u001b[38;5;124m'\u001b[39m], config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPAD_TOKEN\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/Documents/UNI/Extrakurrikular/dkst/dkst/utils/KST_utils.py:314\u001b[0m, in \u001b[0;36mcompute_conditionals\u001b[0;34m(K, p_k, beta, eta, factor, powerset)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;66;03m# Compute conditional probability of each response pattern given the knowledge structure\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, pattern \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(rho\u001b[38;5;241m.\u001b[39mkeys()):\n\u001b[0;32m--> 314\u001b[0m     rho[pattern] \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_rho\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpowerset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp_k\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m    316\u001b[0m conditionals \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mlist\u001b[39m(rho\u001b[38;5;241m.\u001b[39mvalues()))\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conditionals\n",
      "File \u001b[0;32m~/Documents/UNI/Extrakurrikular/dkst/dkst/utils/KST_utils.py:262\u001b[0m, in \u001b[0;36mcompute_rho\u001b[0;34m(R, K_matrix, beta, eta, p_k)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(p_k)): \n\u001b[1;32m    261\u001b[0m     state \u001b[38;5;241m=\u001b[39m K_matrix[i]\n\u001b[0;32m--> 262\u001b[0m     r_value \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_r\u001b[49m\u001b[43m(\u001b[49m\u001b[43mR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m     rho_R \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m r_value \u001b[38;5;241m*\u001b[39m p_k[i]\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rho_R\n",
      "File \u001b[0;32m~/Documents/UNI/Extrakurrikular/dkst/dkst/utils/KST_utils.py:209\u001b[0m, in \u001b[0;36mcompute_r\u001b[0;34m(R, k, beta, eta)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m LG_response[i]: \n\u001b[1;32m    208\u001b[0m     prob \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m eta\n\u001b[0;32m--> 209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mCE_response\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m:\n\u001b[1;32m    210\u001b[0m     prob \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m beta\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m correct_response[i]:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Dataset configuration \n",
    "D0 = DKSTDataset02(config_path)\n",
    "\n",
    "# split dataset 80/20\n",
    "train_size = int(0.8 * len(D0))\n",
    "test_size = len(D0) - train_size\n",
    "D_train, D_test = random_split(D0, [train_size, test_size])\n",
    "\n",
    "sample = D_train.__getitem__(0)\n",
    "print()\n",
    "print(\"Length train set: \", len(D_train))\n",
    "print(\"Shape conditionals:       \", sample[0].shape)\n",
    "print(\"Shape input sequence:     \", sample[1].shape) \n",
    "print(\"Shape target sequence:    \", sample[2].shape) \n",
    "print(\"Shape input observations: \", sample[3].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "model = CustomDecoderModel(config_path)\n",
    "device = model.config[\"device\"]\n",
    "model = model.to(device)\n",
    "\n",
    "dataloader = DataLoader(D_train, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# get one batch \n",
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    print()\n",
    "    print(\"Batch size: \", len(sample_batched))\n",
    "    print(\"Shape conditionals:       \", sample_batched[0].shape)\n",
    "    print(\"Shape input sequence:     \", sample_batched[1].shape) \n",
    "    print(\"Shape target sequence:    \", sample_batched[2].shape) \n",
    "    print(\"Shape input observations: \", sample_batched[3].shape)\n",
    "\n",
    "    # Histogram to vizualize conditionals\n",
    "    conditionals = sample_batched[0].numpy()[0]\n",
    "    colors = ['green' if i in sample_batched[2][0] else 'red' for i in range(len(conditionals))]\n",
    "    colors[0] = 'green'\n",
    "    print(\"Conditionals histogram:\")\n",
    "    plt.bar(range(len(conditionals)), conditionals.flatten(), color=colors)\n",
    "    plt.show()\n",
    "\n",
    "    # Histogram to vizualize input observations\n",
    "    input_obs = sample_batched[3].numpy()[0]\n",
    "    print(\"Input observations histogram:\")\n",
    "    plt.bar(range(len(input_obs)), input_obs.flatten(), color=colors)\n",
    "    plt.show()\n",
    "    break\n",
    "\n",
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    conditionals, input_seq, target_seq, input_obs = sample_batched\n",
    "    conditionals = conditionals.to(device)\n",
    "    input_seq = input_seq.to(device)\n",
    "    target_seq = target_seq.to(device)\n",
    "    input_obs = input_obs.to(device)\n",
    "    output, embedding, attention_weights = model.forward(conditionals, input_seq)\n",
    "    print()\n",
    "    print(\"Output shape: \", output.shape) \n",
    "    print(\"Embedding shape: \", embedding.shape)\n",
    "    print()\n",
    "    \n",
    "    print(\"Attention weights:\")\n",
    "    for i, attn_weight in enumerate(attention_weights):\n",
    "        print(f\"Layer {i} attention weights shape: {attn_weight.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_dataset(D_train, data_type=\"train\")\n",
    "# save_dataset(D_test, data_type=\"test\")\n",
    "\n",
    "# D_train  = load_dataset(\"dataset_train_Q6_50.pth\")\n",
    "# D_test   = load_dataset(\"dataset_test_Q6_50.pth\")\n",
    "\n",
    "# class FilteredDataset(Dataset):\n",
    "#     def __init__(self, data):\n",
    "#         self.data = data\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         return self.data[idx]\n",
    "\n",
    "# def filter_dataset(D, max_length=4):\n",
    "#     D_filtered = []\n",
    "#     # Get eos token id from a Subset of a ConcatDataset...\n",
    "#     #eos_token_id = D.dataset.datasets[0].datasets[0].datasets[0].datasets[0].vocab_size - 2\n",
    "#     eos_token_id = D.dataset.datasets[0].vocab_size - 2\n",
    "\n",
    "#     for conditionals, input_seq, target_seq, input_obs in D:\n",
    "#         if input_seq[max_length] < eos_token_id:\n",
    "#             D_filtered.append((conditionals, input_seq, target_seq, input_obs))\n",
    "    \n",
    "#     filtered_dataset = FilteredDataset(D_filtered)\n",
    "\n",
    "#     return filtered_dataset\n",
    "\n",
    "# # Filter for seqeunces with length <= 2**5\n",
    "# D_test_filtered = filter_dataset(D_test, max_length=32)\n",
    "# D_train_filtered = filter_dataset(D_train, max_length=32)\n",
    "\n",
    "# print(\"Length of filtered train set: \", len(D_train_filtered))\n",
    "# print(\"Length of filtered test set: \", len(D_test_filtered))\n",
    "\n",
    "# D_test_original = D_test\n",
    "# D_train_original = D_train\n",
    "# D_test = D_test_filtered\n",
    "# D_train = D_train_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomDecoderModel(config_path) \n",
    "device = model.config[\"device\"]\n",
    "model = model.to(device)\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader = DataLoader(D_train, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "eval_loader = DataLoader(D_test, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "ce_loss = CustomCELoss()\n",
    "ln_loss = LengthNormLoss()\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "clip_norm = 1.0\n",
    "n_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln_wheight = 0.0\n",
    "penalty_weight = 0.0\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "Train CE Loss: 0.3583, Train LN Loss: 0.0000, Train Combined Loss: 0.3583\n",
      "Eval CE Loss: 0.3106, Eval LN Loss: 0.0000, Eval Combined Loss: 0.3106\n",
      "\n",
      "Allocated memory: 344.79052734375 MB |  Driver allocated memory: 1232.78125 MB\n",
      "Epoch 2/50\n",
      "Train CE Loss: 0.2879, Train LN Loss: 0.0000, Train Combined Loss: 0.2879\n",
      "Eval CE Loss: 0.2756, Eval LN Loss: 0.0000, Eval Combined Loss: 0.2756\n",
      "\n",
      "Allocated memory: 353.271484375 MB |  Driver allocated memory: 1240.78125 MB\n",
      "Epoch 3/50\n",
      "Train CE Loss: 0.2294, Train LN Loss: 0.0000, Train Combined Loss: 0.2294\n",
      "Eval CE Loss: 0.2183, Eval LN Loss: 0.0000, Eval Combined Loss: 0.2183\n",
      "\n",
      "Allocated memory: 357.93408203125 MB |  Driver allocated memory: 1248.78125 MB\n",
      "Epoch 4/50\n",
      "Train CE Loss: 0.1862, Train LN Loss: 0.0000, Train Combined Loss: 0.1862\n",
      "Eval CE Loss: 0.1555, Eval LN Loss: 0.0000, Eval Combined Loss: 0.1555\n",
      "\n",
      "Allocated memory: 362.8603515625 MB |  Driver allocated memory: 1248.78125 MB\n",
      "Epoch 5/50\n",
      "Train CE Loss: 0.1569, Train LN Loss: 0.0000, Train Combined Loss: 0.1569\n",
      "Eval CE Loss: 0.1663, Eval LN Loss: 0.0000, Eval Combined Loss: 0.1663\n",
      "\n",
      "Allocated memory: 361.84033203125 MB |  Driver allocated memory: 1256.78125 MB\n",
      "Epoch 6/50\n",
      "Train CE Loss: 0.1396, Train LN Loss: 0.0000, Train Combined Loss: 0.1396\n",
      "Eval CE Loss: 0.1458, Eval LN Loss: 0.0000, Eval Combined Loss: 0.1458\n",
      "\n",
      "Allocated memory: 361.8173828125 MB |  Driver allocated memory: 1248.78125 MB\n",
      "Epoch 7/50\n",
      "Train CE Loss: 0.1293, Train LN Loss: 0.0000, Train Combined Loss: 0.1293\n",
      "Eval CE Loss: 0.1305, Eval LN Loss: 0.0000, Eval Combined Loss: 0.1305\n",
      "\n",
      "Allocated memory: 361.8125 MB |  Driver allocated memory: 1248.78125 MB\n",
      "Epoch 8/50\n",
      "Train CE Loss: 0.1223, Train LN Loss: 0.0000, Train Combined Loss: 0.1223\n",
      "Eval CE Loss: 0.1387, Eval LN Loss: 0.0000, Eval Combined Loss: 0.1387\n",
      "\n",
      "Allocated memory: 362.7841796875 MB |  Driver allocated memory: 1248.78125 MB\n",
      "Epoch 9/50\n",
      "Train CE Loss: 0.1171, Train LN Loss: 0.0000, Train Combined Loss: 0.1171\n",
      "Eval CE Loss: 0.1174, Eval LN Loss: 0.0000, Eval Combined Loss: 0.1174\n",
      "\n",
      "Allocated memory: 361.81396484375 MB |  Driver allocated memory: 1248.78125 MB\n",
      "Epoch 10/50\n",
      "Train CE Loss: 0.1142, Train LN Loss: 0.0000, Train Combined Loss: 0.1142\n",
      "Eval CE Loss: 0.1270, Eval LN Loss: 0.0000, Eval Combined Loss: 0.1270\n",
      "\n",
      "Allocated memory: 362.78369140625 MB |  Driver allocated memory: 1256.78125 MB\n",
      "Epoch 11/50\n",
      "Train CE Loss: 0.1111, Train LN Loss: 0.0000, Train Combined Loss: 0.1111\n",
      "Eval CE Loss: 0.1167, Eval LN Loss: 0.0000, Eval Combined Loss: 0.1167\n",
      "\n",
      "Allocated memory: 362.7841796875 MB |  Driver allocated memory: 1256.78125 MB\n",
      "Epoch 12/50\n",
      "Train CE Loss: 0.1096, Train LN Loss: 0.0000, Train Combined Loss: 0.1096\n",
      "Eval CE Loss: 0.1071, Eval LN Loss: 0.0000, Eval Combined Loss: 0.1071\n",
      "\n",
      "Allocated memory: 361.8125 MB |  Driver allocated memory: 1256.78125 MB\n",
      "Epoch 13/50\n",
      "Train CE Loss: 0.1075, Train LN Loss: 0.0000, Train Combined Loss: 0.1075\n",
      "Eval CE Loss: 0.1168, Eval LN Loss: 0.0000, Eval Combined Loss: 0.1168\n",
      "\n",
      "Allocated memory: 361.8125 MB |  Driver allocated memory: 1256.78125 MB\n",
      "Epoch 14/50\n",
      "Train CE Loss: 0.1071, Train LN Loss: 0.0000, Train Combined Loss: 0.1071\n",
      "Eval CE Loss: 0.1119, Eval LN Loss: 0.0000, Eval Combined Loss: 0.1119\n",
      "\n",
      "Allocated memory: 361.8466796875 MB |  Driver allocated memory: 1256.78125 MB\n",
      "Epoch 15/50\n",
      "Train CE Loss: 0.1055, Train LN Loss: 0.0000, Train Combined Loss: 0.1055\n",
      "Eval CE Loss: 0.1038, Eval LN Loss: 0.0000, Eval Combined Loss: 0.1038\n",
      "\n",
      "Allocated memory: 361.81298828125 MB |  Driver allocated memory: 1264.78125 MB\n",
      "Epoch 16/50\n",
      "Train CE Loss: 0.1049, Train LN Loss: 0.0000, Train Combined Loss: 0.1049\n",
      "Eval CE Loss: 0.1150, Eval LN Loss: 0.0000, Eval Combined Loss: 0.1150\n",
      "\n",
      "Allocated memory: 361.8466796875 MB |  Driver allocated memory: 1264.78125 MB\n",
      "Epoch 17/50\n",
      "Train CE Loss: 0.1048, Train LN Loss: 0.0000, Train Combined Loss: 0.1048\n",
      "Eval CE Loss: 0.1101, Eval LN Loss: 0.0000, Eval Combined Loss: 0.1101\n",
      "\n",
      "Allocated memory: 361.84814453125 MB |  Driver allocated memory: 1256.78125 MB\n",
      "Epoch 18/50\n",
      "Train CE Loss: 0.1041, Train LN Loss: 0.0000, Train Combined Loss: 0.1041\n",
      "Eval CE Loss: 0.1077, Eval LN Loss: 0.0000, Eval Combined Loss: 0.1077\n",
      "\n",
      "Allocated memory: 362.55517578125 MB |  Driver allocated memory: 1264.78125 MB\n",
      "Epoch 19/50\n",
      "Train CE Loss: 0.1035, Train LN Loss: 0.0000, Train Combined Loss: 0.1035\n",
      "Eval CE Loss: 0.1027, Eval LN Loss: 0.0000, Eval Combined Loss: 0.1027\n",
      "\n",
      "Allocated memory: 361.80908203125 MB |  Driver allocated memory: 1264.78125 MB\n",
      "Epoch 20/50\n",
      "Train CE Loss: 0.1037, Train LN Loss: 0.0000, Train Combined Loss: 0.1037\n",
      "Eval CE Loss: 0.1016, Eval LN Loss: 0.0000, Eval Combined Loss: 0.1016\n",
      "\n",
      "Allocated memory: 361.810546875 MB |  Driver allocated memory: 1264.78125 MB\n",
      "Epoch 21/50\n",
      "Train CE Loss: 0.1027, Train LN Loss: 0.0000, Train Combined Loss: 0.1027\n",
      "Eval CE Loss: 0.1130, Eval LN Loss: 0.0000, Eval Combined Loss: 0.1130\n",
      "\n",
      "Allocated memory: 362.78076171875 MB |  Driver allocated memory: 1272.78125 MB\n",
      "Epoch 22/50\n",
      "Train CE Loss: 0.1025, Train LN Loss: 0.0000, Train Combined Loss: 0.1025\n",
      "Eval CE Loss: 0.1092, Eval LN Loss: 0.0000, Eval Combined Loss: 0.1092\n",
      "\n",
      "Allocated memory: 361.8095703125 MB |  Driver allocated memory: 1272.78125 MB\n",
      "Epoch 23/50\n",
      "Train CE Loss: 0.1032, Train LN Loss: 0.0000, Train Combined Loss: 0.1032\n",
      "Eval CE Loss: 0.1024, Eval LN Loss: 0.0000, Eval Combined Loss: 0.1024\n",
      "\n",
      "Allocated memory: 362.78076171875 MB |  Driver allocated memory: 1272.78125 MB\n",
      "Epoch 24/50\n",
      "Train CE Loss: 0.1028, Train LN Loss: 0.0000, Train Combined Loss: 0.1028\n",
      "Eval CE Loss: 0.1029, Eval LN Loss: 0.0000, Eval Combined Loss: 0.1029\n",
      "\n",
      "Allocated memory: 361.810546875 MB |  Driver allocated memory: 1272.78125 MB\n",
      "Epoch 25/50\n",
      "Train CE Loss: 0.1024, Train LN Loss: 0.0000, Train Combined Loss: 0.1024\n",
      "Eval CE Loss: 0.1034, Eval LN Loss: 0.0000, Eval Combined Loss: 0.1034\n",
      "\n",
      "Allocated memory: 362.78076171875 MB |  Driver allocated memory: 1272.78125 MB\n",
      "Epoch 26/50\n",
      "Train CE Loss: 0.1025, Train LN Loss: 0.0000, Train Combined Loss: 0.1025\n",
      "Eval CE Loss: 0.1015, Eval LN Loss: 0.0000, Eval Combined Loss: 0.1015\n",
      "\n",
      "Allocated memory: 361.8095703125 MB |  Driver allocated memory: 1272.78125 MB\n",
      "Epoch 27/50\n",
      "Train CE Loss: 0.1026, Train LN Loss: 0.0000, Train Combined Loss: 0.1026\n",
      "Eval CE Loss: 0.0981, Eval LN Loss: 0.0000, Eval Combined Loss: 0.0981\n",
      "\n",
      "Allocated memory: 361.81103515625 MB |  Driver allocated memory: 1272.78125 MB\n",
      "Epoch 28/50\n",
      "Train CE Loss: 0.1026, Train LN Loss: 0.0000, Train Combined Loss: 0.1026\n",
      "Eval CE Loss: 0.0937, Eval LN Loss: 0.0000, Eval Combined Loss: 0.0937\n",
      "\n",
      "Allocated memory: 362.78076171875 MB |  Driver allocated memory: 1280.78125 MB\n",
      "Epoch 29/50\n",
      "Train CE Loss: 0.1021, Train LN Loss: 0.0000, Train Combined Loss: 0.1021\n",
      "Eval CE Loss: 0.0940, Eval LN Loss: 0.0000, Eval Combined Loss: 0.0940\n",
      "\n",
      "Allocated memory: 362.78125 MB |  Driver allocated memory: 1272.78125 MB\n",
      "Epoch 30/50\n",
      "Train CE Loss: 0.1020, Train LN Loss: 0.0000, Train Combined Loss: 0.1020\n",
      "Eval CE Loss: 0.0962, Eval LN Loss: 0.0000, Eval Combined Loss: 0.0962\n",
      "\n",
      "Allocated memory: 361.8125 MB |  Driver allocated memory: 1280.78125 MB\n",
      "Epoch 31/50\n",
      "Train CE Loss: 0.1019, Train LN Loss: 0.0000, Train Combined Loss: 0.1019\n",
      "Eval CE Loss: 0.1023, Eval LN Loss: 0.0000, Eval Combined Loss: 0.1023\n",
      "\n",
      "Allocated memory: 361.84521484375 MB |  Driver allocated memory: 1272.78125 MB\n",
      "Epoch 32/50\n",
      "Train CE Loss: 0.1021, Train LN Loss: 0.0000, Train Combined Loss: 0.1021\n",
      "Eval CE Loss: 0.0989, Eval LN Loss: 0.0000, Eval Combined Loss: 0.0989\n",
      "\n",
      "Allocated memory: 361.81005859375 MB |  Driver allocated memory: 1272.78125 MB\n",
      "Epoch 33/50\n",
      "Train CE Loss: 0.1015, Train LN Loss: 0.0000, Train Combined Loss: 0.1015\n",
      "Eval CE Loss: 0.0996, Eval LN Loss: 0.0000, Eval Combined Loss: 0.0996\n",
      "\n",
      "Allocated memory: 361.81005859375 MB |  Driver allocated memory: 1272.78125 MB\n",
      "Epoch 34/50\n",
      "Train CE Loss: 0.1021, Train LN Loss: 0.0000, Train Combined Loss: 0.1021\n",
      "Eval CE Loss: 0.0965, Eval LN Loss: 0.0000, Eval Combined Loss: 0.0965\n",
      "\n",
      "Allocated memory: 362.78076171875 MB |  Driver allocated memory: 1280.78125 MB\n",
      "Epoch 35/50\n",
      "Train CE Loss: 0.1018, Train LN Loss: 0.0000, Train Combined Loss: 0.1018\n",
      "Eval CE Loss: 0.0976, Eval LN Loss: 0.0000, Eval Combined Loss: 0.0976\n",
      "\n",
      "Allocated memory: 361.80908203125 MB |  Driver allocated memory: 1280.78125 MB\n",
      "Epoch 36/50\n",
      "Train CE Loss: 0.1020, Train LN Loss: 0.0000, Train Combined Loss: 0.1020\n",
      "Eval CE Loss: 0.0978, Eval LN Loss: 0.0000, Eval Combined Loss: 0.0978\n",
      "\n",
      "Allocated memory: 361.81103515625 MB |  Driver allocated memory: 1280.78125 MB\n",
      "Epoch 37/50\n",
      "Train CE Loss: 0.1017, Train LN Loss: 0.0000, Train Combined Loss: 0.1017\n",
      "Eval CE Loss: 0.0976, Eval LN Loss: 0.0000, Eval Combined Loss: 0.0976\n",
      "\n",
      "Allocated memory: 361.81201171875 MB |  Driver allocated memory: 1280.78125 MB\n",
      "Epoch 38/50\n",
      "Train CE Loss: 0.1013, Train LN Loss: 0.0000, Train Combined Loss: 0.1013\n",
      "Eval CE Loss: 0.0956, Eval LN Loss: 0.0000, Eval Combined Loss: 0.0956\n",
      "\n",
      "Allocated memory: 362.78076171875 MB |  Driver allocated memory: 1280.78125 MB\n",
      "Epoch 39/50\n",
      "Train CE Loss: 0.1018, Train LN Loss: 0.0000, Train Combined Loss: 0.1018\n",
      "Eval CE Loss: 0.0966, Eval LN Loss: 0.0000, Eval Combined Loss: 0.0966\n",
      "\n",
      "Allocated memory: 362.77978515625 MB |  Driver allocated memory: 1280.78125 MB\n",
      "Epoch 40/50\n",
      "Train CE Loss: 0.1012, Train LN Loss: 0.0000, Train Combined Loss: 0.1012\n",
      "Eval CE Loss: 0.0974, Eval LN Loss: 0.0000, Eval Combined Loss: 0.0974\n",
      "\n",
      "Allocated memory: 361.8095703125 MB |  Driver allocated memory: 1280.78125 MB\n",
      "Epoch 41/50\n",
      "Train CE Loss: 0.1014, Train LN Loss: 0.0000, Train Combined Loss: 0.1014\n",
      "Eval CE Loss: 0.0960, Eval LN Loss: 0.0000, Eval Combined Loss: 0.0960\n",
      "\n",
      "Allocated memory: 362.77978515625 MB |  Driver allocated memory: 1280.78125 MB\n",
      "Epoch 42/50\n",
      "Train CE Loss: 0.1017, Train LN Loss: 0.0000, Train Combined Loss: 0.1017\n",
      "Eval CE Loss: 0.0969, Eval LN Loss: 0.0000, Eval Combined Loss: 0.0969\n",
      "\n",
      "Allocated memory: 361.81103515625 MB |  Driver allocated memory: 1280.78125 MB\n",
      "Epoch 43/50\n",
      "Train CE Loss: 0.1019, Train LN Loss: 0.0000, Train Combined Loss: 0.1019\n",
      "Eval CE Loss: 0.0971, Eval LN Loss: 0.0000, Eval Combined Loss: 0.0971\n",
      "\n",
      "Allocated memory: 361.81005859375 MB |  Driver allocated memory: 1280.78125 MB\n",
      "Epoch 44/50\n",
      "Train CE Loss: 0.1016, Train LN Loss: 0.0000, Train Combined Loss: 0.1016\n",
      "Eval CE Loss: 0.0967, Eval LN Loss: 0.0000, Eval Combined Loss: 0.0967\n",
      "\n",
      "Allocated memory: 362.78076171875 MB |  Driver allocated memory: 1280.78125 MB\n",
      "Epoch 45/50\n",
      "Train CE Loss: 0.1020, Train LN Loss: 0.0000, Train Combined Loss: 0.1020\n",
      "Eval CE Loss: 0.0969, Eval LN Loss: 0.0000, Eval Combined Loss: 0.0969\n",
      "\n",
      "Allocated memory: 362.78076171875 MB |  Driver allocated memory: 1280.78125 MB\n",
      "Epoch 46/50\n",
      "Train CE Loss: 0.1021, Train LN Loss: 0.0000, Train Combined Loss: 0.1021\n",
      "Eval CE Loss: 0.0959, Eval LN Loss: 0.0000, Eval Combined Loss: 0.0959\n",
      "\n",
      "Allocated memory: 361.81005859375 MB |  Driver allocated memory: 1280.78125 MB\n",
      "Epoch 47/50\n",
      "Train CE Loss: 0.1019, Train LN Loss: 0.0000, Train Combined Loss: 0.1019\n",
      "Eval CE Loss: 0.0961, Eval LN Loss: 0.0000, Eval Combined Loss: 0.0961\n",
      "\n",
      "Allocated memory: 362.7802734375 MB |  Driver allocated memory: 1282.78125 MB\n",
      "Epoch 48/50\n",
      "Train CE Loss: 0.1026, Train LN Loss: 0.0000, Train Combined Loss: 0.1026\n",
      "Eval CE Loss: 0.0962, Eval LN Loss: 0.0000, Eval Combined Loss: 0.0962\n",
      "\n",
      "Allocated memory: 361.810546875 MB |  Driver allocated memory: 1284.78125 MB\n",
      "Epoch 49/50\n",
      "Train CE Loss: 0.1017, Train LN Loss: 0.0000, Train Combined Loss: 0.1017\n",
      "Eval CE Loss: 0.0961, Eval LN Loss: 0.0000, Eval Combined Loss: 0.0961\n",
      "\n",
      "Allocated memory: 361.80810546875 MB |  Driver allocated memory: 1284.78125 MB\n",
      "Epoch 50/50\n",
      "Train CE Loss: 0.1018, Train LN Loss: 0.0000, Train Combined Loss: 0.1018\n",
      "Eval CE Loss: 0.0962, Eval LN Loss: 0.0000, Eval Combined Loss: 0.0962\n",
      "\n",
      "Allocated memory: 362.7802734375 MB |  Driver allocated memory: 1284.78125 MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Start tracing memory allocations\n",
    "#tracemalloc.start()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Training\n",
    "    train_ce_loss, train_ln_loss, train_combined_loss = train(\n",
    "        model, train_loader, ce_loss, ln_loss, ln_wheight, optimizer, penalty_weight=penalty_weight, clip_norm=clip_norm, knet=None, device=device, prediction_only=False\n",
    "    )                                                                               # 0.3\n",
    "    # Evaluation\n",
    "    eval_ce_loss, eval_ln_loss, eval_combined_loss = eval(\n",
    "        model, eval_loader, ce_loss, ln_loss, ln_wheight, knet=None, penalty_weight=penalty_weight, device=device, prediction_only=False\n",
    "    )\n",
    "\n",
    "    #mean_ce, mean_ln, mean_combined = eval_with_mc(model, eval_loader, ce_loss, ln_loss, ln_wheight, knet=None, prediction_only=False, n_mc_samples=3)\n",
    "    \n",
    "    # Print training and evaluation metrics\n",
    "    print(f\"Epoch {epoch+1}/{n_epochs}\")\n",
    "    print(f\"Train CE Loss: {train_ce_loss:.4f}, Train LN Loss: {train_ln_loss:.4f}, Train Combined Loss: {train_combined_loss:.4f}\")\n",
    "    print(f\"Eval CE Loss: {eval_ce_loss:.4f}, Eval LN Loss: {eval_ln_loss:.4f}, Eval Combined Loss: {eval_combined_loss:.4f}\")\n",
    "    #print(f\"MCDP CE Loss: {mean_ce:.4f}, MCDP LN Loss: {mean_ln:.4f}, MCDP Combined Loss: {mean_combined:.4f}\")\n",
    "    \n",
    "    # Step the learning rate scheduler\n",
    "    lr_scheduler.step()\n",
    "    penalty_weight = max(0, penalty_weight - 0.05)\n",
    "    ln_wheight *= 0.75\n",
    "    print()\n",
    "\n",
    "\n",
    "    # Clear cache and run garbage collector\n",
    "    if model.config[\"device\"] == \"mps\":\n",
    "        torch.mps.empty_cache()\n",
    "    elif model.config[\"device\"] == \"cuda\":\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "# Stop tracing memory allocations\n",
    "#tracemalloc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do: Fix penalty loss, such that it only considers states prior to eos in the target sequence (and approaches 0 earli on in training), or remove... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target sequence:     [0, 1, 3, 4, 9, 14, 15, 22, 24, 25, 26, 31, 34, 38, 42, 43, 44, 47, 48, 49, 50, 56, 57, 58, 60, 62, 63, 64]\n",
      "Generated sequence:  [0, 1, 3, 4, 5, 9, 10, 11, 14, 15, 16, 22, 24, 25, 26, 27, 31, 34, 38, 42, 43, 44, 47, 48, 49, 50, 51, 56, 57, 58, 60, 62, 63, 64]\n",
      "MCDP sequence:       [0, 1, 3, 4, 9, 14, 15, 22, 24, 25, 26, 31, 34, 38, 42, 43, 44, 47, 48, 49, 50, 56, 57, 58, 60, 62, 63, 64]\n",
      "Embedding shape:  torch.Size([1, 1024])\n",
      "Target sequence:     [0, 3, 5, 6, 7, 12, 14, 16, 18, 20, 23, 25, 27, 28, 30, 31, 36, 37, 39, 42, 43, 45, 46, 47, 48, 51, 53, 55, 58, 63, 64]\n",
      "Generated sequence:  [0, 1, 2, 3, 5, 6, 7, 8, 9, 12, 14, 16, 18, 20, 23, 25, 27, 28, 30, 31, 32, 36, 37, 39, 40, 42, 43, 45, 46, 47, 48, 51, 53, 55, 58, 59, 63, 64]\n",
      "MCDP sequence:       [0, 3, 5, 6, 7, 12, 14, 16, 18, 20, 23, 25, 27, 28, 30, 31, 36, 37, 39, 42, 43, 45, 46, 47, 48, 51, 53, 55, 58, 63, 64]\n",
      "Embedding shape:  torch.Size([1, 1024])\n",
      "Target sequence:     [0, 1, 2, 3, 4, 6, 10, 21, 22, 23, 24, 25, 27, 29, 30, 31, 33, 35, 36, 37, 38, 42, 43, 47, 52, 53, 54, 55, 56, 57, 60, 61, 62, 63, 64]\n",
      "Generated sequence:  [0, 1, 2, 3, 4, 6, 7, 10, 11, 12, 14, 15, 17, 18, 21, 22, 23, 24, 25, 27, 29, 30, 31, 33, 35, 36, 37, 38, 39, 42, 43, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 60, 61, 62, 63, 64]\n",
      "MCDP sequence:       [0, 1, 2, 3, 4, 6, 10, 11, 13, 16, 21, 22, 23, 24, 25, 27, 29, 30, 31, 33, 35, 36, 37, 38, 42, 43, 47, 48, 52, 53, 54, 55, 56, 57, 60, 61, 62, 63, 64]\n",
      "Embedding shape:  torch.Size([1, 1024])\n",
      "Target sequence:     [0, 1, 2, 6, 7, 8, 9, 10, 11, 13, 14, 15, 17, 22, 23, 24, 25, 26, 27, 32, 34, 36, 39, 40, 42, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 57, 59, 62, 63, 64]\n",
      "Generated sequence:  [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 13, 14, 15, 17, 18, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 34, 36, 37, 39, 40, 42, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 57, 59, 62, 63, 64]\n",
      "MCDP sequence:       [0, 1, 2, 6, 7, 8, 9, 10, 11, 13, 14, 15, 17, 22, 23, 24, 25, 26, 27, 28, 32, 34, 36, 39, 40, 42, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 57, 59, 62, 63, 64]\n",
      "Embedding shape:  torch.Size([1, 1024])\n",
      "Target sequence:     [0, 1, 6, 9, 10, 11, 12, 13, 16, 20, 21, 25, 26, 29, 30, 33, 34, 35, 39, 42, 43, 44, 47, 53, 56, 57, 59, 60, 61, 63, 64]\n",
      "Generated sequence:  [0, 1, 2, 3, 4, 6, 9, 10, 11, 12, 13, 16, 20, 21, 22, 23, 25, 26, 29, 30, 33, 34, 35, 36, 39, 42, 43, 44, 47, 48, 49, 50, 53, 56, 57, 59, 60, 61, 63, 64]\n",
      "MCDP sequence:       [0, 1, 2, 6, 9, 10, 11, 12, 13, 16, 20, 21, 25, 26, 29, 30, 33, 34, 35, 39, 42, 43, 44, 47, 53, 56, 57, 59, 60, 61, 63, 64]\n",
      "Embedding shape:  torch.Size([1, 1024])\n",
      "Target sequence:     [0, 1, 2, 4, 5, 8, 10, 11, 12, 13, 14, 15, 16, 19, 20, 24, 26, 28, 29, 30, 34, 38, 40, 46, 48, 49, 51, 52, 53, 54, 55, 56, 59, 60, 61, 62, 63, 64]\n",
      "Generated sequence:  [0, 1, 2, 4, 5, 8, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 24, 26, 28, 29, 30, 31, 34, 35, 36, 38, 40, 41, 42, 46, 48, 49, 51, 52, 53, 54, 55, 56, 59, 60, 61, 62, 63, 64]\n",
      "MCDP sequence:       [0, 1, 2, 4, 5, 8, 10, 11, 12, 13, 14, 15, 16, 19, 20, 24, 26, 28, 29, 30, 34, 38, 40, 46, 48, 49, 51, 52, 53, 54, 55, 56, 59, 60, 61, 62, 63, 64]\n",
      "Embedding shape:  torch.Size([1, 1024])\n",
      "Target sequence:     [0, 1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 19, 21, 26, 27, 28, 29, 33, 34, 35, 38, 39, 40, 42, 45, 46, 47, 50, 51, 57, 58, 63, 64]\n",
      "Generated sequence:  [0, 1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 33, 34, 35, 38, 39, 40, 42, 45, 46, 47, 50, 51, 52, 53, 54, 57, 58, 59, 63, 64]\n",
      "MCDP sequence:       [0, 1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 19, 21, 26, 27, 28, 29, 33, 34, 35, 38, 39, 40, 42, 45, 46, 47, 50, 51, 54, 57, 58, 63, 64]\n",
      "Embedding shape:  torch.Size([1, 1024])\n",
      "Target sequence:     [0, 3, 6, 9, 11, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 36, 37, 40, 42, 44, 45, 48, 50, 52, 59, 63, 64]\n",
      "Generated sequence:  [0, 1, 2, 3, 6, 9, 11, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 36, 37, 40, 42, 44, 45, 48, 50, 52, 53, 54, 56, 59, 63, 64]\n",
      "MCDP sequence:       [0, 3, 6, 9, 11, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 36, 37, 40, 42, 44, 45, 48, 50, 52, 59, 63, 64]\n",
      "Embedding shape:  torch.Size([1, 1024])\n",
      "Target sequence:     [0, 1, 3, 5, 6, 8, 9, 14, 17, 19, 21, 24, 27, 28, 29, 32, 35, 36, 37, 42, 43, 44, 48, 49, 50, 54, 55, 61, 63, 64]\n",
      "Generated sequence:  [0, 1, 3, 5, 6, 8, 9, 10, 11, 14, 17, 19, 21, 22, 24, 27, 28, 29, 32, 35, 36, 37, 38, 40, 42, 43, 44, 45, 48, 49, 50, 54, 55, 56, 57, 59, 61, 63, 64]\n",
      "MCDP sequence:       [0, 1, 3, 5, 6, 8, 9, 14, 17, 19, 21, 24, 27, 28, 29, 32, 35, 36, 37, 42, 43, 44, 48, 49, 50, 54, 55, 61, 63, 64]\n",
      "Embedding shape:  torch.Size([1, 1024])\n",
      "Target sequence:     [0, 1, 3, 4, 9, 11, 14, 15, 17, 18, 22, 26, 27, 28, 30, 32, 36, 38, 40, 42, 48, 49, 50, 51, 55, 57, 58, 60, 62, 63, 64]\n",
      "Generated sequence:  [0, 1, 2, 3, 4, 5, 6, 9, 11, 14, 15, 17, 18, 22, 23, 24, 26, 27, 28, 30, 32, 36, 38, 40, 42, 43, 45, 48, 49, 50, 51, 52, 55, 57, 58, 60, 62, 63, 64]\n",
      "MCDP sequence:       [0, 1, 3, 4, 9, 11, 14, 15, 17, 18, 22, 26, 27, 28, 30, 32, 36, 38, 40, 42, 48, 49, 50, 51, 55, 57, 58, 60, 62, 63, 64]\n",
      "Embedding shape:  torch.Size([1, 1024])\n"
     ]
    }
   ],
   "source": [
    "# Clear cache and run garbage collector\n",
    "if model.config[\"device\"] == \"mps\":\n",
    "    torch.mps.empty_cache()\n",
    "elif model.config[\"device\"] == \"cuda\":\n",
    "    torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# Print memory usage\n",
    "# print(\"Allocated memory:\", torch.mps.current_allocated_memory() / (1024 ** 2), \"MB | \", \n",
    "#         f\"Driver allocated memory: {torch.mps.driver_allocated_memory() / (1024 ** 2)} MB\")\n",
    "\n",
    "for i in range(10):\n",
    "    #conditionals, input_seq, target_seq, input_obs =  D2[0]\n",
    "    dataloader = DataLoader(D_test, batch_size=1, shuffle=True, collate_fn=collate_fn)\n",
    "    # Fetch a sample from the DataLoader\n",
    "    for conditionals, input_seq, target_seq, input_obs in dataloader:\n",
    "        break  # We only need one sample\n",
    "    conditionals = conditionals.to(device)\n",
    "    input_seq = input_seq.to(device)\n",
    "    input_obs = input_obs.to(device)\n",
    "\n",
    "    seq, emb = generate_sequence(model, conditionals.to(device), device=device)\n",
    "    seq_MCDP, emb_MCDP = generate_sequence_MCDP(model, conditionals.to(device), device=device)\n",
    "    print(\"Target sequence:    \", [t for t in [0]+target_seq.tolist()[0] if t != model.vocab_size-1])\n",
    "    print(\"Generated sequence: \", seq)\n",
    "    print(\"MCDP sequence:      \", seq_MCDP)\n",
    "    print(\"Embedding shape: \", emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance test without MC dropout.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing performance with MCDP disabled...: 100%|██████████| 100/100 [00:18<00:00,  5.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:       0.0\n",
      "Mean distance:  7.75\n",
      "Std:            2.68467875173176\n",
      "Performance test with MC dropout and 2 mcdp runs per sample.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing performance with MCDP enabled...: 100%|██████████| 100/100 [00:31<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:       0.05\n",
      "Mean distance:  3.52\n",
      "Std:            2.104661492972207\n",
      "\n",
      "Performance test with MC dropout and 3 mcdp runs per sample.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing performance with MCDP enabled...: 100%|██████████| 100/100 [00:43<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:       0.35\n",
      "Mean distance:  1.55\n",
      "Std:            1.6635804759614128\n",
      "\n",
      "Performance test with MC dropout and 5 mcdp runs per sample.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing performance with MCDP enabled...: 100%|██████████| 100/100 [01:06<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:       0.52\n",
      "Mean distance:  0.96\n",
      "Std:            1.4347125147568764\n",
      "\n",
      "Performance test with MC dropout and 30 mcdp runs per sample.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing performance with MCDP enabled...: 100%|██████████| 100/100 [06:08<00:00,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:       0.73\n",
      "Mean distance:  0.43\n",
      "Std:            0.8155366331440912\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Performance test without MC dropout.\")\n",
    "acc, mean, std = performance(model, dataloader, num_samples=100)\n",
    "print(\"Accuracy:      \", acc)\n",
    "print(\"Mean distance: \", mean)\n",
    "print(\"Std:           \", std)\n",
    "\n",
    "n_mc_samples = [2,3,5,30]\n",
    "for i in n_mc_samples:\n",
    "    print(f\"Performance test with MC dropout and {i} mcdp runs per sample.\")\n",
    "    acc, mean, std = performance(model, dataloader, n_mc_samples=i, num_samples=100)\n",
    "    print(\"Accuracy:      \", acc)\n",
    "    print(\"Mean distance: \", mean)\n",
    "    print(\"Std:           \", std)\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_model(model, \"model_Q6_01.pth\", optimizer, epoch=50)\n",
    "\n",
    "#model_re = CustomDecoderModel(config_path)\n",
    "#model_re, optimizer_re, epoch_re= load_model(model_re, \"model_Q6_00.pth\")\n",
    "\n",
    "#model = model_re\n",
    "#model = model.to(model.config[\"device\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dkst-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
