{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules reloaded and re-imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Reload all modules in case they are under development\n",
    "import importlib\n",
    "from dkst.utils import KST_utils, DKST_utils, set_operations, relations\n",
    "from dkst import dkst_datasets, models\n",
    "\n",
    "# Reload each module\n",
    "importlib.reload(KST_utils)\n",
    "importlib.reload(DKST_utils)\n",
    "importlib.reload(set_operations)\n",
    "importlib.reload(relations)\n",
    "importlib.reload(dkst_datasets)\n",
    "importlib.reload(models)\n",
    "\n",
    "# Import everything from the modules\n",
    "from dkst.utils.KST_utils import *\n",
    "from dkst.utils.DKST_utils import *\n",
    "from dkst.utils.set_operations import *\n",
    "from dkst.utils.relations import *\n",
    "from dkst.dkst_datasets import *\n",
    "from dkst.models import *\n",
    "\n",
    "import gc\n",
    "import tracemalloc\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "print(\"Modules reloaded and re-imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset configuration \n",
    "config_path = os.path.abspath(\"../data/config/config_data_04.1.json\")\n",
    "D0 = DKSTDataset02(config_path)\n",
    "for i in [2,3,4,5]:\n",
    "    config_path = os.path.abspath(f\"../data/config/config_data_04.{i}.json\")\n",
    "    D0 += DKSTDataset02(config_path)\n",
    "\n",
    "# split dataset 80/20\n",
    "train_size = int(0.8 * len(D0))\n",
    "test_size = len(D0) - train_size\n",
    "D_train, D_test = random_split(D0, [train_size, test_size])\n",
    "#D4 = D2 + D3\n",
    "\n",
    "sample = D_train.__getitem__(0)\n",
    "print()\n",
    "print(\"Length train set: \", len(D_train))\n",
    "print(\"Shape conditionals:       \", sample[0].shape)\n",
    "print(\"Shape input sequence:     \", sample[1].shape) \n",
    "print(\"Shape target sequence:    \", sample[2].shape) \n",
    "print(\"Shape input observations: \", sample[3].shape)\n",
    "\n",
    "# model\n",
    "model = CustomDecoderModel(config_path)\n",
    "device = \"mps\"\n",
    "model = model.to(device)\n",
    "\n",
    "dataloader = DataLoader(D_train, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "# get one batch \n",
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    print()\n",
    "    print(\"Batch size: \", len(sample_batched))\n",
    "    print(\"Shape conditionals:       \", sample_batched[0].shape)\n",
    "    print(\"Shape input sequence:     \", sample_batched[1].shape) \n",
    "    print(\"Shape target sequence:    \", sample_batched[2].shape) \n",
    "    print(\"Shape input observations: \", sample_batched[3].shape)\n",
    "    break\n",
    "\n",
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    conditionals, input_seq, target_seq, input_obs = sample_batched\n",
    "    conditionals = conditionals.to(device)\n",
    "    input_seq = input_seq.to(device)\n",
    "    target_seq = target_seq.to(device)\n",
    "    input_obs = input_obs.to(device)\n",
    "    output, embedding, attention_weights = model.forward(conditionals, input_seq)\n",
    "    print()\n",
    "    print(\"Output shape: \", output.shape) \n",
    "    print(\"Embedding shape: \", embedding.shape)\n",
    "    print()\n",
    "    \n",
    "    print(\"Attention weights:\")\n",
    "    for i, attn_weight in enumerate(attention_weights):\n",
    "        print(f\"Layer {i} attention weights shape: {attn_weight.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomDecoderModel(config_path) \n",
    "device = \"mps\" #\"cpu\"\n",
    "model = model.to(device)\n",
    "batch_size = 4\n",
    "\n",
    "train_loader = DataLoader(D_train, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "eval_loader = DataLoader(D_test, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "ce_loss = CustomCELoss()\n",
    "ln_loss = LengthNormLoss()\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "clip_norm = 2\n",
    "n_epochs = 70\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln_wheight = 0.001\n",
    "penalty_weight = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "Train CE Loss: 0.0991, Train LN Loss: 0.0000, Train Combined Loss: 0.0991\n",
      "Eval CE Loss: 0.0111, Eval LN Loss: 0.0000, Eval Combined Loss: 0.0111\n",
      "\n",
      "Allocated memory: 369.6015625 MB |  Driver allocated memory: 12395.296875 MB\n",
      "Epoch 2/15\n",
      "Train CE Loss: 0.0999, Train LN Loss: 0.0000, Train Combined Loss: 0.0999\n",
      "Eval CE Loss: 0.0119, Eval LN Loss: 0.0000, Eval Combined Loss: 0.0119\n",
      "\n",
      "Allocated memory: 370.5537109375 MB |  Driver allocated memory: 12371.296875 MB\n",
      "Epoch 3/15\n",
      "Train CE Loss: 0.0995, Train LN Loss: 0.0000, Train Combined Loss: 0.0995\n",
      "Eval CE Loss: 0.0115, Eval LN Loss: 0.0000, Eval Combined Loss: 0.0116\n",
      "\n",
      "Allocated memory: 370.5537109375 MB |  Driver allocated memory: 12749.296875 MB\n",
      "Epoch 4/15\n",
      "Train CE Loss: 0.0996, Train LN Loss: 0.0000, Train Combined Loss: 0.0996\n",
      "Eval CE Loss: 0.0118, Eval LN Loss: 0.0000, Eval Combined Loss: 0.0118\n",
      "\n",
      "Allocated memory: 370.55419921875 MB |  Driver allocated memory: 13487.296875 MB\n",
      "Epoch 5/15\n",
      "Train CE Loss: 0.0989, Train LN Loss: 0.0000, Train Combined Loss: 0.0989\n",
      "Eval CE Loss: 0.0108, Eval LN Loss: 0.0000, Eval Combined Loss: 0.0108\n",
      "\n",
      "Allocated memory: 369.583984375 MB |  Driver allocated memory: 14171.296875 MB\n",
      "Epoch 6/15\n",
      "Train CE Loss: 0.0996, Train LN Loss: 0.0000, Train Combined Loss: 0.0996\n",
      "Eval CE Loss: 0.0106, Eval LN Loss: 0.0000, Eval Combined Loss: 0.0106\n",
      "\n",
      "Allocated memory: 369.5830078125 MB |  Driver allocated memory: 14869.296875 MB\n",
      "Epoch 7/15\n",
      "Train CE Loss: 0.0992, Train LN Loss: 0.0000, Train Combined Loss: 0.0992\n",
      "Eval CE Loss: 0.0104, Eval LN Loss: 0.0000, Eval Combined Loss: 0.0104\n",
      "\n",
      "Allocated memory: 369.58203125 MB |  Driver allocated memory: 15607.296875 MB\n",
      "Epoch 8/15\n",
      "Train CE Loss: 0.0992, Train LN Loss: 0.0000, Train Combined Loss: 0.0992\n",
      "Eval CE Loss: 0.0103, Eval LN Loss: 0.0000, Eval Combined Loss: 0.0103\n",
      "\n",
      "Allocated memory: 370.32568359375 MB |  Driver allocated memory: 16429.296875 MB\n",
      "Epoch 9/15\n",
      "Train CE Loss: 0.0994, Train LN Loss: 0.0000, Train Combined Loss: 0.0994\n",
      "Eval CE Loss: 0.0104, Eval LN Loss: 0.0000, Eval Combined Loss: 0.0104\n",
      "\n",
      "Allocated memory: 371.29638671875 MB |  Driver allocated memory: 17451.296875 MB\n",
      "Epoch 10/15\n",
      "Train CE Loss: 0.0992, Train LN Loss: 0.0000, Train Combined Loss: 0.0992\n",
      "Eval CE Loss: 0.0104, Eval LN Loss: 0.0000, Eval Combined Loss: 0.0104\n",
      "\n",
      "Allocated memory: 371.29638671875 MB |  Driver allocated memory: 18173.296875 MB\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 361.26 MB, other allocations: 17.77 GB, max allowed: 18.13 GB). Tried to allocate 12.00 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Start tracing memory allocations\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#tracemalloc.start()\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     train_ce_loss, train_ln_loss, train_combined_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mce_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mln_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mln_wheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpenalty_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpenalty_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclip_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mknet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m                                                                               \u001b[38;5;66;03m# 0.3\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Evaluation\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     eval_ce_loss, eval_ln_loss, eval_combined_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(\n\u001b[1;32m     11\u001b[0m         model, eval_loader, ce_loss, ln_loss, ln_wheight, knet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, penalty_weight\u001b[38;5;241m=\u001b[39mpenalty_weight, device\u001b[38;5;241m=\u001b[39mdevice, prediction_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/UNI/Extrakurrikular/dkst/dkst/models.py:519\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, ce_loss, ln_loss, ln_wheight, optimizer, penalty_weight, clip_norm, knet, device, prediction_only)\u001b[0m\n\u001b[1;32m    516\u001b[0m total_loss_combiened \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_combined\n\u001b[1;32m    518\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m \u001b[43mloss_combined\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), clip_norm)\n\u001b[1;32m    521\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/Documents/UNI/Extrakurrikular/dkst/dkst-env/lib/python3.9/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/UNI/Extrakurrikular/dkst/dkst-env/lib/python3.9/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 361.26 MB, other allocations: 17.77 GB, max allowed: 18.13 GB). Tried to allocate 12.00 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "\n",
    "# Start tracing memory allocations\n",
    "#tracemalloc.start()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Training\n",
    "    train_ce_loss, train_ln_loss, train_combined_loss = train(\n",
    "        model, train_loader, ce_loss, ln_loss, ln_wheight, optimizer, penalty_weight=penalty_weight, clip_norm=clip_norm, knet=None, device=device, prediction_only=False\n",
    "    )                                                                               # 0.3\n",
    "    # Evaluation\n",
    "    eval_ce_loss, eval_ln_loss, eval_combined_loss = eval(\n",
    "        model, eval_loader, ce_loss, ln_loss, ln_wheight, knet=None, penalty_weight=penalty_weight, device=device, prediction_only=False\n",
    "    )\n",
    "\n",
    "    #mean_ce, mean_ln, mean_combined = eval_with_mc(model, eval_loader, ce_loss, ln_loss, ln_wheight, knet=None, prediction_only=False, n_mc_samples=3)\n",
    "    \n",
    "    # Print training and evaluation metrics\n",
    "    print(f\"Epoch {epoch+1}/{n_epochs}\")\n",
    "    print(f\"Train CE Loss: {train_ce_loss:.4f}, Train LN Loss: {train_ln_loss:.4f}, Train Combined Loss: {train_combined_loss:.4f}\")\n",
    "    print(f\"Eval CE Loss: {eval_ce_loss:.4f}, Eval LN Loss: {eval_ln_loss:.4f}, Eval Combined Loss: {eval_combined_loss:.4f}\")\n",
    "    #print(f\"MCDP CE Loss: {mean_ce:.4f}, MCDP LN Loss: {mean_ln:.4f}, MCDP Combined Loss: {mean_combined:.4f}\")\n",
    "    \n",
    "    # Step the learning rate scheduler\n",
    "    lr_scheduler.step()\n",
    "    penalty_weight = max(0, penalty_weight - 0.1)\n",
    "    ln_wheight *= 0.75\n",
    "    print()\n",
    "\n",
    "    # Print memory usage\n",
    "    #current, peak = tracemalloc.get_traced_memory()\n",
    "    print(\"Allocated memory:\", torch.mps.current_allocated_memory() / (1024 ** 2), \"MB | \", \n",
    "          f\"Driver allocated memory: {torch.mps.driver_allocated_memory() / (1024 ** 2)} MB\")\n",
    "\n",
    "    # Clear cache and run garbage collector\n",
    "    torch.mps.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "# Stop tracing memory allocations\n",
    "#tracemalloc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do: Fix penalty loss, such that it only considers states prior to eos in the target sequence (and approaches 0 earli on in training), or remove... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target sequence:     [0, 3, 7, 15, 16, 18, 20, 24, 25, 27, 29, 30, 31, 32, 33, 36, 37, 39, 40, 42, 45, 46, 48, 49, 50, 51, 52, 55, 56, 59, 62, 63, 64]\n",
      "Generated sequence:  [0, 3, 7, 15, 16, 18, 20, 24, 25, 27, 29, 30, 31, 32, 33, 36, 37, 39, 40, 42, 45, 46, 48, 49, 50, 51, 52, 55, 56, 59, 62, 63, 64]\n",
      "MCDP sequence:       [0, 3, 7, 14, 15, 16, 18, 20, 24, 25, 27, 29, 30, 31, 32, 33, 36, 37, 39, 40, 42, 45, 46, 48, 49, 50, 51, 52, 55, 56, 59, 62, 63, 64]\n",
      "Embedding shape:  torch.Size([1, 1024])\n",
      "Target sequence:     [0, 3, 4, 9, 10, 13, 14, 15, 16, 20, 23, 26, 30, 31, 32, 33, 36, 38, 39, 40, 44, 45, 50, 52, 53, 54, 56, 58, 60, 62, 63, 64]\n",
      "Generated sequence:  [0, 3, 4, 6, 9, 10, 13, 14, 15, 16, 20, 23, 26, 30, 31, 32, 33, 36, 38, 39, 40, 44, 45, 50, 52, 53, 54, 56, 58, 60, 62, 63, 64]\n",
      "MCDP sequence:       [0, 3, 4, 9, 10, 13, 14, 15, 16, 20, 23, 26, 30, 31, 32, 33, 36, 38, 39, 40, 44, 45, 50, 52, 53, 54, 56, 58, 60, 62, 63, 64]\n",
      "Embedding shape:  torch.Size([1, 1024])\n",
      "Target sequence:     [0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 37, 38, 39, 43, 46, 47, 48, 53, 55, 58, 60, 61, 63, 64]\n",
      "Generated sequence:  [0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 37, 38, 39, 43, 46, 47, 48, 53, 55, 58, 60, 61, 63, 64]\n",
      "MCDP sequence:       [0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 37, 38, 39, 43, 46, 47, 48, 53, 55, 58, 60, 61, 63, 64]\n",
      "Embedding shape:  torch.Size([1, 1024])\n",
      "Target sequence:     [0, 2, 11, 14, 15, 17, 18, 19, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 37, 38, 40, 41, 42, 43, 45, 47, 48, 52, 55, 56, 58, 62, 63, 64]\n",
      "Generated sequence:  [0, 2, 5, 11, 14, 15, 17, 18, 19, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 37, 38, 40, 41, 42, 43, 45, 47, 48, 52, 55, 56, 58, 62, 63, 64]\n",
      "MCDP sequence:       [0, 2, 5, 11, 14, 15, 17, 18, 19, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 37, 38, 40, 41, 42, 43, 45, 47, 48, 52, 55, 56, 58, 62, 63, 64]\n",
      "Embedding shape:  torch.Size([1, 1024])\n",
      "Target sequence:     [0, 8, 10, 11, 12, 16, 17, 19, 21, 22, 30, 33, 36, 37, 40, 42, 44, 45, 47, 52, 53, 54, 57, 58, 59, 60, 62, 63, 64]\n",
      "Generated sequence:  [0, 7, 9, 11, 12, 16, 17, 19, 21, 22, 30, 33, 36, 37, 40, 42, 44, 45, 47, 52, 53, 54, 57, 58, 59, 60, 62, 63, 64]\n",
      "MCDP sequence:       [0, 7, 9, 11, 12, 16, 17, 19, 21, 22, 26, 30, 33, 36, 37, 40, 42, 44, 45, 47, 52, 53, 54, 57, 58, 59, 60, 62, 63, 64]\n",
      "Embedding shape:  torch.Size([1, 1024])\n",
      "Target sequence:     [0, 1, 2, 4, 7, 8, 10, 12, 14, 16, 18, 23, 25, 30, 33, 34, 41, 42, 43, 44, 45, 47, 52, 53, 54, 55, 63, 64]\n",
      "Generated sequence:  [0, 1, 2, 4, 7, 8, 10, 12, 14, 16, 18, 23, 25, 30, 33, 34, 41, 42, 43, 44, 45, 47, 52, 53, 54, 55, 63, 64]\n",
      "MCDP sequence:       [0, 1, 2, 4, 7, 8, 10, 12, 14, 16, 18, 23, 25, 30, 33, 34, 41, 42, 43, 44, 45, 47, 52, 53, 54, 55, 59, 63, 64]\n",
      "Embedding shape:  torch.Size([1, 1024])\n",
      "Target sequence:     [0, 1, 2, 4, 5, 6, 7, 8, 9, 12, 16, 18, 20, 21, 23, 24, 25, 28, 29, 30, 33, 37, 38, 42, 44, 47, 53, 57, 58, 59, 60, 61, 62, 63, 64]\n",
      "Generated sequence:  [0, 1, 2, 4, 5, 6, 7, 8, 9, 12, 16, 18, 20, 21, 23, 24, 25, 28, 29, 30, 32, 37, 38, 42, 44, 47, 53, 57, 58, 59, 60, 61, 62, 63, 64]\n",
      "MCDP sequence:       [0, 1, 2, 4, 5, 6, 7, 8, 9, 12, 16, 18, 20, 21, 23, 24, 25, 28, 29, 30, 33, 37, 38, 42, 44, 47, 51, 52, 54, 57, 58, 59, 60, 61, 62, 63, 64]\n",
      "Embedding shape:  torch.Size([1, 1024])\n",
      "Target sequence:     [0, 8, 14, 15, 16, 17, 18, 22, 23, 24, 25, 28, 29, 31, 32, 34, 41, 42, 47, 51, 53, 54, 58, 61, 62, 63, 64]\n",
      "Generated sequence:  [0, 8, 14, 15, 16, 17, 18, 22, 23, 24, 25, 28, 29, 31, 32, 34, 41, 42, 47, 51, 53, 54, 58, 61, 62, 63, 64]\n",
      "MCDP sequence:       [0, 5, 8, 14, 15, 16, 17, 18, 22, 23, 24, 25, 28, 29, 31, 32, 34, 37, 41, 42, 47, 51, 53, 54, 58, 61, 62, 63, 64]\n",
      "Embedding shape:  torch.Size([1, 1024])\n",
      "Target sequence:     [0, 2, 3, 4, 11, 14, 15, 19, 20, 22, 24, 25, 27, 30, 31, 32, 33, 34, 39, 40, 43, 46, 47, 49, 51, 52, 55, 57, 60, 63, 64]\n",
      "Generated sequence:  [0, 2, 3, 4, 6, 11, 14, 15, 19, 20, 22, 24, 25, 27, 30, 31, 32, 33, 34, 39, 40, 43, 46, 47, 49, 51, 52, 55, 57, 60, 63, 64]\n",
      "MCDP sequence:       [0, 2, 3, 4, 11, 14, 15, 19, 20, 22, 24, 25, 27, 30, 31, 32, 33, 34, 39, 40, 43, 46, 47, 49, 51, 52, 55, 57, 60, 63, 64]\n",
      "Embedding shape:  torch.Size([1, 1024])\n",
      "Target sequence:     [0, 2, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 19, 28, 30, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 49, 50, 54, 57, 58, 63, 64]\n",
      "Generated sequence:  [0, 2, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 19, 21, 28, 30, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 49, 50, 54, 57, 58, 63, 64]\n",
      "MCDP sequence:       [0, 2, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 19, 21, 28, 30, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 49, 50, 54, 57, 58, 63, 64]\n",
      "Embedding shape:  torch.Size([1, 1024])\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    #conditionals, input_seq, target_seq, input_obs =  D2[0]\n",
    "    dataloader = DataLoader(D_test, batch_size=1, shuffle=True, collate_fn=collate_fn)\n",
    "    # Fetch a sample from the DataLoader\n",
    "    for conditionals, input_seq, target_seq, input_obs in dataloader:\n",
    "        break  # We only need one sample\n",
    "    conditionals = conditionals.to(device)\n",
    "    input_seq = input_seq.to(device)\n",
    "    input_obs = input_obs.to(device)\n",
    "\n",
    "    seq, emb = generate_sequence(model, conditionals.to(device), device=device)\n",
    "    seq_MCDP, emb_MCDP = generate_sequence_MCDP(model, conditionals.to(device), device=device)\n",
    "    print(\"Target sequence:    \", [t for t in [0]+target_seq.tolist()[0] if t != model.vocab_size-1])\n",
    "    print(\"Generated sequence: \", seq)\n",
    "    print(\"MCDP sequence:      \", seq_MCDP)\n",
    "    print(\"Embedding shape: \", emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance test without MC dropout.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing performance with MCDP disabled...: 100%|██████████| 100/100 [00:13<00:00,  7.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:       0.74\n",
      "Mean distance:  0.46\n",
      "Std:            1.135077089893017\n",
      "Performance test with MC dropout and 2 mcdp runs per sample.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing performance with MCDP enabled...: 100%|██████████| 100/100 [00:28<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:       0.31\n",
      "Mean distance:  1.88\n",
      "Std:            1.8669761648183942\n",
      "\n",
      "Performance test with MC dropout and 3 mcdp runs per sample.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing performance with MCDP enabled...: 100%|██████████| 100/100 [00:41<00:00,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:       0.62\n",
      "Mean distance:  0.63\n",
      "Std:            1.0455142275454696\n",
      "\n",
      "Performance test with MC dropout and 5 mcdp runs per sample.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing performance with MCDP enabled...: 100%|██████████| 100/100 [01:04<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:       0.67\n",
      "Mean distance:  0.55\n",
      "Std:            1.0712142642814275\n",
      "\n",
      "Performance test with MC dropout and 30 mcdp runs per sample.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing performance with MCDP enabled...: 100%|██████████| 100/100 [06:54<00:00,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:       0.82\n",
      "Mean distance:  0.22\n",
      "Std:            0.5211525688318154\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Performance test without MC dropout.\")\n",
    "acc, mean, std = performance(model, dataloader, num_samples=100)\n",
    "print(\"Accuracy:      \", acc)\n",
    "print(\"Mean distance: \", mean)\n",
    "print(\"Std:           \", std)\n",
    "\n",
    "n_mc_samples = [2,3,5,30]\n",
    "for i in n_mc_samples:\n",
    "    print(f\"Performance test with MC dropout and {i} mcdp runs per sample.\")\n",
    "    acc, mean, std = performance(model, dataloader, n_mc_samples=i, num_samples=100)\n",
    "    print(\"Accuracy:      \", acc)\n",
    "    print(\"Mean distance: \", mean)\n",
    "    print(\"Std:           \", std)\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dkst-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
